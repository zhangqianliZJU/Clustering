{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TBM_smac_Gpyopt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangqianliZJU/Clustering/blob/master/TBM_smac_Gpyopt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0CuQkJ25UTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !apt-get install build-essential swig\n",
        "# !pip install smac\n",
        "# !pip install gpyopt\n",
        "# !mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGaoK9gb7w8A",
        "colab_type": "code",
        "outputId": "7ea4904b-854c-46b5-e93c-c4775fa1c8ed",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c021abe1-2f15-4897-bfc3-8b37b3a3f13f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c021abe1-2f15-4897-bfc3-8b37b3a3f13f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving rock mass properties.csv to rock mass properties.csv\n",
            "User uploaded file \"rock mass properties.csv\" with length 5387 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYCzpE66sdb",
        "colab_type": "code",
        "outputId": "6746e4db-9ebe-4e49-9fff-fc39adb6cdd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "# Import ConfigSpace and different types of parameters\n",
        "from smac.configspace import ConfigurationSpace\n",
        "from ConfigSpace.hyperparameters import CategoricalHyperparameter, \\\n",
        "    UniformFloatHyperparameter, UniformIntegerHyperparameter\n",
        "from ConfigSpace.conditions import InCondition\n",
        "\n",
        "# Import SMAC-utilities\n",
        "from smac.tae.execute_func import ExecuteTAFuncDict\n",
        "from smac.scenario.scenario import Scenario\n",
        "from smac.facade.smac_facade import SMAC\n",
        "from smac.optimizer.acquisition import EI, PI, LCB\n",
        "from smac.epm.rf_with_instances import RandomForestWithInstances\n",
        "from smac.utils.util_funcs import get_types\n",
        "from smac.utils.constants import MAXINT, N_TREES \n",
        "#import gpyopt\n",
        "import GPy\n",
        "import GPyOpt\n",
        "#import random forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#import AdaBoostRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "#import a bagging regressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "#import keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras import losses\n",
        "from keras.utils import plot_model#图像化输出网络结构\n",
        "from keras.layers import LeakyReLU\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "#import normalization methods\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler,StandardScaler\n",
        "# rockMassData = pd.read_csv('rock mass properties.csv',sep = ',')\n",
        "# subRockMassData = rockMassData[['UCS','BTS','PSI','DPW','Alpha angle','Measured ROP']]\n",
        "# subRockMassData['Alpha angle'] = np.sin(subRockMassData['Alpha angle'] * np.pi / 180)\n",
        "# #Min-Max normalization\n",
        "# maxData = subRockMassData.max()\n",
        "# normData = subRockMassData/maxData\n",
        "# totalFeatureLabels = np.array(normData)\n",
        "\n",
        "# inputs = totalFeatureLabels[:,:-1]\n",
        "# outputs = totalFeatureLabels[:,-1]\n",
        "# trainInput,testInput,trainOutput,testOutput = train_test_split(inputs,outputs,train_size = 121,shuffle=True,random_state =123)\n",
        "# # trainInput = inputs[:121,:]#The random split strategy performs better than the random split strategy\n",
        "# # testInput = inputs[121:,:]\n",
        "# # trainOutput = outputs[:121]\n",
        "# # testOutput = outputs[121:]\n",
        "# print(trainInput.shape,testInput.shape,trainOutput.shape,testOutput.shape)\n",
        "\n",
        "def mae(trueOutput,predictOutput):\n",
        "    mae = np.mean(np.abs(trueOutput-predictOutput))\n",
        "    return mae\n",
        "def mape(trueOutput,predictOutput):\n",
        "    mape = np.mean(np.abs(trueOutput-predictOutput)/trueOutput)*100\n",
        "    return mape\n",
        "def coef(trueOutput,predictOutput):\n",
        "    coef = np.corrcoef(trueOutput,predictOutput)\n",
        "    return coef[0,1]\n",
        "# def mse(trueOutput,predictOutput):\n",
        "#     diff = (trueOutput-predictOutput) * maxData[5]\n",
        "#     mse = np.mean(diff ** 2)\n",
        "#     return mse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukYw_3rf_QmD",
        "colab_type": "code",
        "outputId": "35bbe68d-c8d3-4650-f33e-fc521491942d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2204
        }
      },
      "source": [
        "#optimize a svm model with SMAC\n",
        "def svm_from_cfg(cfg):\n",
        "#     print(cfg)\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "#     print(cfg)\n",
        "#     print(type(cfg['degree']))\n",
        "    # We translate boolean values:\n",
        "    cfg[\"shrinking\"] = True if cfg[\"shrinking\"] == \"true\" else False\n",
        "    # And for gamma, we set it to a fixed value or to \"auto\" (if used)\n",
        "    if \"gamma\" in cfg:\n",
        "        cfg[\"gamma\"] = cfg[\"gamma_value\"] if cfg[\"gamma\"] == \"value\" else \"auto\"\n",
        "        cfg.pop(\"gamma_value\", None)  # Remove \"gamma_value\"\n",
        "\n",
        "    svr = svm.SVR(**cfg)\n",
        "    svr.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = svr.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "#     testMAPE = mape(testOutput,predictTestOutput)\n",
        "    testMSE = mse(testOutput,predictTestOutput)\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "#     return testMAPE\n",
        "    return testMSE\n",
        "#     return -testCoef\n",
        "\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "\n",
        "# We define a few possible types of SVM-kernels and add them as \"kernel\" to our cs\n",
        "kernel = CategoricalHyperparameter(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"], default_value=\"poly\")\n",
        "cs.add_hyperparameter(kernel)\n",
        "\n",
        "# There are some hyperparameters shared by all kernels\n",
        "C = UniformFloatHyperparameter(\"C\", 0, 1000.0, default_value=1)#default = 10\n",
        "shrinking = CategoricalHyperparameter(\"shrinking\", [\"true\", \"false\"], default_value=\"true\")\n",
        "cs.add_hyperparameters([C, shrinking])\n",
        "\n",
        "#add epsilon\n",
        "epsilon = UniformFloatHyperparameter(\"epsilon\", 0, 1, default_value=0.1)     # Only used by kernel poly,default = 0.1\n",
        "\n",
        "# Others are kernel-specific, so we can add conditions to limit the searchspace\n",
        "degree = UniformIntegerHyperparameter(\"degree\", 1, 5, default_value=3)     # Only used by kernel poly,default = 3\n",
        "coef0 = UniformFloatHyperparameter(\"coef0\", 0.0, 100.0, default_value=0.0)  # poly, sigmoid, default = 0.0\n",
        "cs.add_hyperparameters([epsilon,degree, coef0])\n",
        "use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n",
        "use_coef0 = InCondition(child=coef0, parent=kernel, values=[\"poly\", \"sigmoid\"])\n",
        "cs.add_conditions([use_degree, use_coef0])\n",
        "\n",
        "# This also works for parameters that are a mix of categorical and values from a range of numbers\n",
        "# For example, gamma can be either \"auto\" or a fixed float\n",
        "gamma = CategoricalHyperparameter(\"gamma\", [\"auto\", \"value\"], default_value=\"auto\")  # only rbf, poly, sigmoid\n",
        "gamma_value = UniformFloatHyperparameter(\"gamma_value\", 0, 20, default_value=10)# default = 3\n",
        "cs.add_hyperparameters([gamma, gamma_value])\n",
        "# We only activate gamma_value if gamma is set to \"value\"\n",
        "cs.add_condition(InCondition(child=gamma_value, parent=gamma, values=[\"value\"]))\n",
        "# And again we can restrict the use of gamma in general to the choice of the kernel\n",
        "cs.add_condition(InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"]))\n",
        "\n",
        "\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 150,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"\n",
        "                     })\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = svm_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=svm_from_cfg,acquisition_function =PI(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = svm_from_cfg(incumbent)\n",
        "\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2019-06-13_14:31:13_546540\n",
            "INFO:smac.facade.smac_facade.SMAC:Optimizing a deterministic scenario for quality without a tuner timeout - will make SMAC deterministic!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Default Value: 0.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0626\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0626\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0626\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0526) is better than incumbent (0.0626) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  C : 1.0 -> 250.11643606976952\n",
            "INFO:smac.intensification.intensification.Intensifier:  coef0 : 0.0 -> 73.17740538538321\n",
            "INFO:smac.intensification.intensification.Intensifier:  degree : 3 -> 1\n",
            "INFO:smac.intensification.intensification.Intensifier:  epsilon : 0.1 -> 0.12018898146944634\n",
            "INFO:smac.intensification.intensification.Intensifier:  gamma : 'auto' -> 'value'\n",
            "INFO:smac.intensification.intensification.Intensifier:  gamma_value : None -> 0.5399290540842805\n",
            "INFO:smac.intensification.intensification.Intensifier:  shrinking : 'true' -> 'false'\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0526\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0526\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0526\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0526\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0444) is better than incumbent (0.0526) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  C : 250.11643606976952 -> 396.6241467116773\n",
            "INFO:smac.intensification.intensification.Intensifier:  coef0 : 73.17740538538321 -> 35.09329833651221\n",
            "INFO:smac.intensification.intensification.Intensifier:  degree : 1 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  epsilon : 0.12018898146944634 -> 0.101385663399844\n",
            "INFO:smac.intensification.intensification.Intensifier:  gamma_value : 0.5399290540842805 -> 18.55962463239884\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0444\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0422) is better than incumbent (0.0444) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  C : 396.6241467116773 -> 86.97260254394268\n",
            "INFO:smac.intensification.intensification.Intensifier:  coef0 : 35.09329833651221 -> 4.730513250108959\n",
            "INFO:smac.intensification.intensification.Intensifier:  degree : 4 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  epsilon : 0.101385663399844 -> 0.10926138349041536\n",
            "INFO:smac.intensification.intensification.Intensifier:  gamma_value : 18.55962463239884 -> 10.634929090470173\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0389) is better than incumbent (0.0422) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  C : 86.97260254394268 -> 991.7643222273297\n",
            "INFO:smac.intensification.intensification.Intensifier:  epsilon : 0.10926138349041536 -> 0.07546816233948195\n",
            "INFO:smac.intensification.intensification.Intensifier:  gamma : 'value' -> 'auto'\n",
            "INFO:smac.intensification.intensification.Intensifier:  kernel : 'poly' -> 'rbf'\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0389\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.stats.stats.Stats:Statistics:\n",
            "INFO:smac.stats.stats.Stats:#Incumbent changed: 4\n",
            "INFO:smac.stats.stats.Stats:#Target algorithm runs: 150 / 150.0\n",
            "INFO:smac.stats.stats.Stats:#Configurations: 150\n",
            "INFO:smac.stats.stats.Stats:Used wallclock time: 400.93 / inf sec \n",
            "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 233.27 / inf sec\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.facade.smac_facade.SMAC:Final Incumbent: Configuration:\n",
            "  C, Value: 991.7643222273297\n",
            "  epsilon, Value: 0.07546816233948195\n",
            "  gamma, Value: 'auto'\n",
            "  kernel, Value: 'rbf'\n",
            "  shrinking, Value: 'false'\n",
            "\n",
            "INFO:smac.facade.smac_facade.SMAC:Estimated cost of incumbent: 0.038936\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimized Value: 0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nP-BUOjAovO",
        "colab_type": "code",
        "outputId": "2f2d1a9d-752f-4454-8cd3-ea88bdaf49c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2559
        }
      },
      "source": [
        "#Optimize a random forest model with smac\n",
        "def rf_from_cfg(cfg):\n",
        "#     print(cfg)\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "#  \n",
        "\n",
        "    rf = RandomForestRegressor(**cfg)\n",
        "    rf.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = rf.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "#     testMAPE = mape(testOutput,predictTestOutput)\n",
        "    testMSE = mse(testOutput,predictTestOutput)\n",
        "\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "#     return testMAPE\n",
        "    return testMSE\n",
        "#     return -testCoef\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "\n",
        "numTrees = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "maxDepth = UniformIntegerHyperparameter(\"max_depth\", 2, 10, default_value=2)# The maximum depth of tree\n",
        "min_samples_split = UniformIntegerHyperparameter(\"min_samples_split\", 2, 6, default_value=2)#The min number of samples required to split an node\n",
        "min_samples_leaf = UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 4, default_value=1)#The min number of samples at a leaf\n",
        "maxFeatures = UniformIntegerHyperparameter(\"max_features\", 3, 5, default_value=5)#The number of maximum features\n",
        "cs.add_hyperparameters([numTrees, maxDepth,min_samples_split,min_samples_leaf,maxFeatures])\n",
        "\n",
        "\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 150,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"\n",
        "                     })\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = rf_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=rf_from_cfg,acquisition_function =PI(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = rf_from_cfg(incumbent)\n",
        "\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2019-06-13_12:55:39_535310\n",
            "INFO:smac.facade.smac_facade.SMAC:Optimizing a deterministic scenario for quality without a tuner timeout - will make SMAC deterministic!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Default Value: 0.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0469) is better than incumbent (0.0577) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 2 -> 10\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 1 -> 2\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 2 -> 5\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 100 -> 33\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0464) is better than incumbent (0.0469) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 5 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 2 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 33 -> 95\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0454) is better than incumbent (0.0464) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 10 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 3 -> 5\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 4 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 5 -> 6\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 95 -> 40\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0454\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0439) is better than incumbent (0.0454) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 4 -> 6\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 5 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 3 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 6 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 40 -> 88\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0439\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0439\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0420) is better than incumbent (0.0439) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 6 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 4 -> 5\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 4 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 3 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 88 -> 73\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0413) is better than incumbent (0.0420) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 4 -> 9\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 4 -> 5\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 73 -> 115\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0413\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0399) is better than incumbent (0.0413) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 9 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 3 -> 2\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 5 -> 2\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 115 -> 71\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0399\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0383) is better than incumbent (0.0399) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 4 -> 8\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 2 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 2 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 71 -> 107\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0383\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.stats.stats.Stats:Statistics:\n",
            "INFO:smac.stats.stats.Stats:#Incumbent changed: 8\n",
            "INFO:smac.stats.stats.Stats:#Target algorithm runs: 150 / 150.0\n",
            "INFO:smac.stats.stats.Stats:#Configurations: 150\n",
            "INFO:smac.stats.stats.Stats:Used wallclock time: 5519.54 / inf sec \n",
            "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 10.44 / inf sec\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.facade.smac_facade.SMAC:Final Incumbent: Configuration:\n",
            "  max_depth, Value: 8\n",
            "  max_features, Value: 5\n",
            "  min_samples_leaf, Value: 3\n",
            "  min_samples_split, Value: 4\n",
            "  n_estimators, Value: 107\n",
            "\n",
            "INFO:smac.facade.smac_facade.SMAC:Estimated cost of incumbent: 0.038323\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimized Value: 0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAlmgTM53Wvt",
        "colab_type": "code",
        "outputId": "688ccc27-2504-450b-f3f2-c4f095b30478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2079
        }
      },
      "source": [
        "#Optimize an adaBoost model with smac\n",
        "def adaBoost_from_cfg(cfg):\n",
        "#     print(cfg)\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "#  \n",
        "\n",
        "    adaBoost = AdaBoostRegressor(**cfg)\n",
        "    adaBoost.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = adaBoost.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "#     testMAPE = mape(testOutput,predictTestOutput)\n",
        "    testMSE = mse(testOutput,predictTestOutput)\n",
        "\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "#     return testMAPE\n",
        "    return testMSE\n",
        "#     return -testCoef\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "\n",
        "numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "learningRate = UniformFloatHyperparameter(\"learning_rate\", 0.1, 10, default_value=1)# The learning rate\n",
        "lossFunction = CategoricalHyperparameter(\"loss\", [\"linear\", \"square\", \"exponential\"], default_value=\"linear\")\n",
        "cs.add_hyperparameters([numEstimators, learningRate,lossFunction])\n",
        "\n",
        "\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 150,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"\n",
        "                     })\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = adaBoost_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=adaBoost_from_cfg,acquisition_function =PI(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = adaBoost_from_cfg(incumbent)\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2019-06-13_12:53:56_655427\n",
            "INFO:smac.facade.smac_facade.SMAC:Optimizing a deterministic scenario for quality without a tuner timeout - will make SMAC deterministic!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Default Value: 0.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0505\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0505\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0505\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0469) is better than incumbent (0.0505) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  learning_rate : 1.0 -> 0.7050512449655166\n",
            "INFO:smac.intensification.intensification.Intensifier:  loss : 'linear' -> 'exponential'\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 100 -> 101\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0469\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0458) is better than incumbent (0.0469) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  learning_rate : 0.7050512449655166 -> 0.6319107615198243\n",
            "INFO:smac.intensification.intensification.Intensifier:  loss : 'exponential' -> 'square'\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 101 -> 74\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0458\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0458\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0458\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0458\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0458\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0458\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0445) is better than incumbent (0.0458) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  learning_rate : 0.6319107615198243 -> 0.5495253172564888\n",
            "INFO:smac.intensification.intensification.Intensifier:  loss : 'square' -> 'linear'\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 74 -> 105\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0445\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0445\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0445\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0445\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0445\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0445\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0422) is better than incumbent (0.0445) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  learning_rate : 0.5495253172564888 -> 1.0423740031047655\n",
            "INFO:smac.intensification.intensification.Intensifier:  loss : 'linear' -> 'square'\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 105 -> 19\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0422\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0411) is better than incumbent (0.0422) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  learning_rate : 1.0423740031047655 -> 0.7524862951292935\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 19 -> 54\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0411\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0411\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0411\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0411\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0411\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0411\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.stats.stats.Stats:Statistics:\n",
            "INFO:smac.stats.stats.Stats:#Incumbent changed: 5\n",
            "INFO:smac.stats.stats.Stats:#Target algorithm runs: 150 / 150.0\n",
            "INFO:smac.stats.stats.Stats:#Configurations: 150\n",
            "INFO:smac.stats.stats.Stats:Used wallclock time: 39.49 / inf sec \n",
            "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 12.98 / inf sec\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.facade.smac_facade.SMAC:Final Incumbent: Configuration:\n",
            "  learning_rate, Value: 0.7524862951292935\n",
            "  loss, Value: 'square'\n",
            "  n_estimators, Value: 54\n",
            "\n",
            "INFO:smac.facade.smac_facade.SMAC:Estimated cost of incumbent: 0.041050\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimized Value: 0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVam_uV6725p",
        "colab_type": "code",
        "outputId": "1b89c7b1-3cf8-4f83-d958-3230125d85c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "#Optimize an BaggingRegressor model with smac\n",
        "def baggingRegressor_from_cfg(cfg):\n",
        "#     print(cfg)\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "    cfg['bootstrap'] = bool(cfg['bootstrap'])\n",
        "    cfg['bootstrap_features'] = bool(cfg['bootstrap_features'])\n",
        "\n",
        "    baggingRegressor = BaggingRegressor(**cfg)\n",
        "    baggingRegressor.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = baggingRegressor.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "    testMAPE = mape(testOutput,predictTestOutput)\n",
        "    testMSE = mse(testOutput,predictTestOutput)\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "#     return testMAPE\n",
        "    return testMSE\n",
        "#     return -testCoef\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "\n",
        "numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 2, 100, default_value=100)#number of estimators\n",
        "maxSamples = UniformFloatHyperparameter(\"max_samples\", 0.5, 1.0, default_value=1.0)# The learning rate\n",
        "maxFeatures = UniformIntegerHyperparameter(\"max_features\", 2,5, default_value=5)\n",
        "boostrap = CategoricalHyperparameter(\"bootstrap\", [\"true\", \"false\"], default_value=\"true\")\n",
        "boostrap2 = CategoricalHyperparameter(\"bootstrap_features\", [\"true\", \"false\"], default_value=\"false\")\n",
        "\n",
        "\n",
        "cs.add_hyperparameters([numEstimators,maxSamples,maxFeatures,boostrap,boostrap2])\n",
        "\n",
        "\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 150,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"\n",
        "                     })\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = baggingRegressor_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=baggingRegressor_from_cfg,acquisition_function =EI(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = baggingRegressor_from_cfg(incumbent)\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-686f448fe337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Example call of the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# It returns: Status, Cost, Runtime, Additional Infos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mdef_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaggingRegressor_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Default Value: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdef_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-686f448fe337>\u001b[0m in \u001b[0;36mbaggingRegressor_from_cfg\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbaggingRegressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbaggingRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpredictTestOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaggingRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     testMAE = mae(testOutput,predictTestOutput)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainInput' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QezJd3IC7Q-E",
        "colab_type": "code",
        "outputId": "77ca265a-d2d4-4ca7-fc1b-605bea84071d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3461
        }
      },
      "source": [
        "# A self implemented AutoML framework\n",
        "# Feature engineering,machine learning model selection, hyperparameter optimization\n",
        "rockMassData = pd.read_csv('rock mass properties.csv',sep = ',')\n",
        "subRockMassData = rockMassData[['UCS','BTS','PSI','DPW','Alpha angle','Measured ROP']]\n",
        "subRockMassData['Alpha angle'] = np.sin(subRockMassData['Alpha angle'] * np.pi / 180)\n",
        "trainInput = None\n",
        "trainOutput = None\n",
        "testInput = None\n",
        "testOutput = None\n",
        "#Normalization methods selection\n",
        "def getNormalizator(norm_method):\n",
        "    normMethod = None\n",
        "    if norm_method == 'standard':\n",
        "        normMethod = StandardScaler\n",
        "    if norm_method == 'min-max':\n",
        "        normMethod = MinMaxScaler\n",
        "    if norm_method == 'max-abs':\n",
        "        normMethod = MaxAbsScaler\n",
        "    return normMethod\n",
        "        \n",
        "    \n",
        "#Model selection\n",
        "def getRegressor(modelName):\n",
        "    regressor = None\n",
        "    if modelName == 'randomForest':\n",
        "        regressor = RandomForestRegressor\n",
        "    if modelName == 'adaBoost':\n",
        "        regressor = AdaBoostRegressor\n",
        "    return regressor        \n",
        "def regressor_from_cfg(cfg):\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "    #Generate model and pop the item\n",
        "    norm_fuck = cfg['norm-method']\n",
        "    cfg.pop('norm-method')\n",
        "    rockMassData = pd.read_csv('rock mass properties.csv',sep = ',')\n",
        "    subRockMassData = rockMassData[['UCS','BTS','PSI','DPW','Alpha angle','Measured ROP']]\n",
        "    subRockMassData['Alpha angle'] = np.sin(subRockMassData['Alpha angle'] * np.pi / 180)\n",
        "    totalFeatureLabels = np.array(subRockMassData)\n",
        "    norm_constructor = getNormalizator(norm_fuck)\n",
        "    normModel = norm_constructor()\n",
        "    normModel.fit_transform(totalFeatureLabels)    \n",
        "    inputs = totalFeatureLabels[:,:-1]\n",
        "    outputs = totalFeatureLabels[:,-1]\n",
        "    trainInput,testInput,trainOutput,testOutput = train_test_split(inputs,outputs,train_size = 121,shuffle=True,random_state =123)\n",
        "    \n",
        "    modelName = cfg['modelName']\n",
        "    regressor = getRegressor(modelName)#Constructor for the specified regressor model    \n",
        "    cfg.pop('modelName')\n",
        "    #Create the regressor model\n",
        "    model = regressor(**cfg)\n",
        "\n",
        "    model.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = model.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "    testMAPE = mape(testOutput,predictTestOutput)\n",
        "#     testMSE = mse(testOutput,predictTestOutput)\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "#     return testMSE\n",
        "    return testMAPE\n",
        "#     return -testCoef\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "#Add the preprocessing option for the AutoML framework TO-DO\n",
        "# Pattern of normalization, The 151 data should be splited sequentially, the former 121 for training\n",
        "#The latter 30 for testing\n",
        "\n",
        "# data prerpocessing\n",
        "norm_methods = CategoricalHyperparameter(\"norm-method\", [\"standard\", \"min-max\",\"max-abs\"], default_value=\"min-max\")\n",
        "# model selection and optimizatio of hyperparameters\n",
        "models = CategoricalHyperparameter(\"modelName\", [\"randomForest\", \"adaBoost\"], default_value=\"adaBoost\")\n",
        "cs.add_hyperparameters([norm_methods,models])\n",
        "#hyperParameters for svr\n",
        "\n",
        "#hyperParameters for random forest\n",
        "numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "maxDepth = UniformIntegerHyperparameter(\"max_depth\", 2, 10, default_value=2)# The maximum depth of tree\n",
        "min_samples_split = UniformIntegerHyperparameter(\"min_samples_split\", 2, 6, default_value=2)#The min number of samples required to split an node\n",
        "min_samples_leaf = UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 4, default_value=1)#The min number of samples at a leaf\n",
        "maxFeatures = UniformIntegerHyperparameter(\"max_features\", 3, 5, default_value=5)#The number of maximum features\n",
        "cs.add_hyperparameters([numEstimators,maxDepth,min_samples_split,min_samples_leaf,maxFeatures])\n",
        "\n",
        "use_maxDepth = InCondition(child=maxDepth, parent=models, values=[\"randomForest\"])\n",
        "use_min_samples_split = InCondition(child=min_samples_split, parent=models, values=[\"randomForest\"])\n",
        "use_min_samples_leaf = InCondition(child=min_samples_leaf, parent=models, values=[\"randomForest\"])\n",
        "use_maxFeatures = InCondition(child=maxFeatures, parent=models, values=[\"randomForest\"])\n",
        "cs.add_conditions([use_maxDepth,use_min_samples_split,use_min_samples_leaf,use_maxFeatures])\n",
        "\n",
        "#hyperParameters for adaBoost\n",
        "# numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "learningRate = UniformFloatHyperparameter(\"learning_rate\", 0.1, 10, default_value=1)# The learning rate\n",
        "lossFunction = CategoricalHyperparameter(\"loss\", [\"linear\", \"square\", \"exponential\"], default_value=\"linear\")\n",
        "cs.add_hyperparameters([learningRate,lossFunction])\n",
        "\n",
        "use_learningRate = InCondition(child=learningRate, parent=models, values=[\"adaBoost\"])\n",
        "use_lossFunction = InCondition(child=lossFunction, parent=models, values=[\"adaBoost\"])\n",
        "\n",
        "cs.add_conditions([use_learningRate, use_lossFunction])\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 300,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"\n",
        "                     })\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = regressor_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=regressor_from_cfg,acquisition_function =EI(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = regressor_from_cfg(incumbent)\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2019-06-11_06:16:11_813173\n",
            "INFO:smac.facade.smac_facade.SMAC:Optimizing a deterministic scenario for quality without a tuner timeout - will make SMAC deterministic!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Default Value: 10.09\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.intensification.intensification.Intensifier:Challenger (9.6565) is better than incumbent (10.5126) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : None -> 7\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : None -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : None -> 1\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : None -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  modelName : 'adaBoost' -> 'randomForest'\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 100 -> 46\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.6565\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.6565\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.6565\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.6565\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (9.4850) is better than incumbent (9.6565) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 3 -> 5\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 1 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 3 -> 2\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 46 -> 72\n",
            "INFO:smac.intensification.intensification.Intensifier:  norm-method : 'min-max' -> 'standard'\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.4850\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.4850\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.4850\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.4850\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (9.3039) is better than incumbent (9.4850) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 7 -> 6\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_split : 2 -> 6\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 72 -> 139\n",
            "INFO:smac.intensification.intensification.Intensifier:  norm-method : 'standard' -> 'max-abs'\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.3039\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (9.0557) is better than incumbent (9.3039) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 6 -> 5\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 5 -> 3\n",
            "INFO:smac.intensification.intensification.Intensifier:  min_samples_leaf : 3 -> 2\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 139 -> 40\n",
            "INFO:smac.intensification.intensification.Intensifier:  norm-method : 'max-abs' -> 'standard'\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 9.0557\n",
            "INFO:smac.intensification.intensification.Intensifier:Challenger (8.8790) is better than incumbent (9.0557) on 1 runs.\n",
            "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_depth : 5 -> 10\n",
            "INFO:smac.intensification.intensification.Intensifier:  max_features : 3 -> 4\n",
            "INFO:smac.intensification.intensification.Intensifier:  n_estimators : 40 -> 36\n",
            "INFO:smac.intensification.intensification.Intensifier:  norm-method : 'standard' -> 'min-max'\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 8.8790\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.stats.stats.Stats:Statistics:\n",
            "INFO:smac.stats.stats.Stats:#Incumbent changed: 5\n",
            "INFO:smac.stats.stats.Stats:#Target algorithm runs: 300 / 300.0\n",
            "INFO:smac.stats.stats.Stats:#Configurations: 300\n",
            "INFO:smac.stats.stats.Stats:Used wallclock time: 1668.25 / inf sec \n",
            "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 65.85 / inf sec\n",
            "INFO:smac.stats.stats.Stats:##########################################################\n",
            "INFO:smac.facade.smac_facade.SMAC:Final Incumbent: Configuration:\n",
            "  max_depth, Value: 10\n",
            "  max_features, Value: 4\n",
            "  min_samples_leaf, Value: 2\n",
            "  min_samples_split, Value: 6\n",
            "  modelName, Value: 'randomForest'\n",
            "  n_estimators, Value: 36\n",
            "  norm-method, Value: 'min-max'\n",
            "\n",
            "INFO:smac.facade.smac_facade.SMAC:Estimated cost of incumbent: 8.879018\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimized Value: 10.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sI_Z-VisVTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A self implemented AutoML framework with three regressors:svr,random forest,adaboost\n",
        "# Feature engineering,machine learning model selection, hyperparameter optimization\n",
        "# def mse(trueOutput,predictOutput):\n",
        "#     diff = (trueOutput-predictOutput)\n",
        "#     mse = np.mean(diff ** 2)\n",
        "#     return mse\n",
        "#Normalization methods selection\n",
        "def getNormalizator(norm_method):\n",
        "    normMethod = None\n",
        "    if norm_method == 'standard':\n",
        "        normMethod = StandardScaler\n",
        "    if norm_method == 'min-max':\n",
        "        normMethod = MinMaxScaler\n",
        "    if norm_method == 'max-abs':\n",
        "        normMethod = MaxAbsScaler\n",
        "    return normMethod\n",
        "\n",
        "#Model selection\n",
        "def getRegressor(modelName):\n",
        "    regressor = None\n",
        "    if modelName == 'randomForest':\n",
        "        regressor = RandomForestRegressor\n",
        "    if modelName == 'adaBoost':\n",
        "        regressor = AdaBoostRegressor\n",
        "    if modelName == 'svr':\n",
        "        regressor = svm.SVR\n",
        "    return regressor        \n",
        "def regressor_from_cfg(cfg):\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "    #Generate model and pop the item\n",
        "    norm_fuck = cfg['norm-method']\n",
        "    cfg.pop('norm-method')\n",
        "    rockMassData = pd.read_csv('rock mass properties.csv',sep = ',')\n",
        "    subRockMassData = rockMassData[['UCS','BTS','PSI','DPW','Alpha angle','Measured ROP']]\n",
        "    subRockMassData['Alpha angle'] = np.sin(subRockMassData['Alpha angle'] * np.pi / 180)\n",
        "    totalFeatureLabels = np.array(subRockMassData)\n",
        "    norm_constructor = getNormalizator(norm_fuck)\n",
        "    normModel = norm_constructor()\n",
        "    totalFeatureLabels_scaled = normModel.fit_transform(totalFeatureLabels)    \n",
        "    inputs = totalFeatureLabels_scaled[:,:-1]\n",
        "    outputs = totalFeatureLabels_scaled[:,-1]\n",
        "#     trainInput,testInput,trainOutput,_ = train_test_split(inputs,outputs,train_size = 121,shuffle=True,random_state =123)\n",
        "    trainInput = inputs[:121,:]#The random split strategy performs better than the random split strategy\n",
        "    testInput = inputs[121:,:]\n",
        "    trainOutput = outputs[:121]\n",
        "    testOutput = outputs[121:]    \n",
        "    modelName = cfg['modelName']\n",
        "    if modelName == 'svr':\n",
        "        print(cfg)\n",
        "        cfg[\"shrinking\"] = True if cfg[\"shrinking\"] == \"true\" else False\n",
        "        if \"gamma\" in cfg:\n",
        "            cfg[\"gamma\"] = cfg[\"gamma_value\"] if cfg[\"gamma\"] == \"value\" else \"auto\"\n",
        "            cfg.pop(\"gamma_value\", None)  # Remove \"gamma_value\"\n",
        "    regressor = getRegressor(modelName)#Constructor for the specified regressor model    \n",
        "    cfg.pop('modelName')\n",
        "    #Create the regressor model\n",
        "    model = regressor(**cfg)\n",
        "\n",
        "    model.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = model.predict(testInput)\n",
        "    restored = np.zeros((30,6))\n",
        "    restored[:,:5] = testInput\n",
        "    restored[:,5] = predictTestOutput\n",
        "    restored_predict = normModel.inverse_transform(restored)\n",
        "\t\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "#     testMAPE = mape(testOutput,predictTestOutput)\n",
        "    testMSE = mse(totalFeatureLabels[121:,5],restored_predict[:,5])\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "    return testMSE\n",
        "#    return testMAPE\n",
        "#     return -testCoef\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "#Add the preprocessing option for the AutoML framework TO-DO\n",
        "# Pattern of normalization, The 151 data should be splited sequentially, the former 121 for training\n",
        "#The latter 30 for testing\n",
        "\n",
        "# data prerpocessing\n",
        "norm_methods = CategoricalHyperparameter(\"norm-method\", [\"standard\", \"min-max\",\"max-abs\"], default_value=\"min-max\")\n",
        "# model selection and optimizatio of hyperparameters\n",
        "models = CategoricalHyperparameter(\"modelName\", [\"randomForest\", \"adaBoost\",\"svr\"], default_value=\"svr\")\n",
        "cs.add_hyperparameters([norm_methods,models])\n",
        "\n",
        "#hyperParameters for svr: C, kernel, shrinking, degree <- kernel:poly, coef0 <- poly, sigmoid, gamma <-rbf, \"poly, sigmoid\n",
        "# We define a few possible types of SVM-kernels and add them as \"kernel\" to our cs\n",
        "kernel = CategoricalHyperparameter(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"], default_value=\"poly\")\n",
        "C = UniformFloatHyperparameter(\"C\", 0, 1000.0, default_value=1)#default = 10\n",
        "shrinking = CategoricalHyperparameter(\"shrinking\", [\"true\", \"false\"], default_value=\"true\")\n",
        "cs.add_hyperparameters([kernel,C, shrinking])\n",
        "use_C = InCondition(child=C,parent=models,values=[\"svr\"])\n",
        "use_kernel = InCondition(child=kernel,parent=models,values=[\"svr\"])\n",
        "use_shrinking = InCondition(child=shrinking,parent=models,values=[\"svr\"])\n",
        "cs.add_conditions([use_kernel,use_C,use_shrinking])\n",
        "\n",
        "# Others are kernel-specific, so we can add conditions to limit the searchspace\n",
        "degree = UniformIntegerHyperparameter(\"degree\", 1, 5, default_value=3)     # Only used by kernel poly,default = 3\n",
        "coef0 = UniformFloatHyperparameter(\"coef0\", 0.0, 100.0, default_value=0.0)  # poly, sigmoid, default = 0.0\n",
        "cs.add_hyperparameters([degree, coef0])\n",
        "\n",
        "use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n",
        "use_coef0 = InCondition(child=coef0, parent=kernel, values=[\"poly\", \"sigmoid\"])\n",
        "\n",
        "# use_degree = InCondition(child=degree, parent=models, values=[\"svr\"])\n",
        "# use_coef0 = InCondition(child=coef0, parent=models, values=[\"svr\"])\n",
        "cs.add_conditions([use_degree, use_coef0])\n",
        "\n",
        "# This also works for parameters that are a mix of categorical and values from a range of numbers\n",
        "# For example, gamma can be either \"auto\" or a fixed float\n",
        "gamma = CategoricalHyperparameter(\"gamma\", [\"auto\", \"value\"], default_value=\"auto\")  # only rbf, poly, sigmoid\n",
        "gamma_value = UniformFloatHyperparameter(\"gamma_value\", 0, 20, default_value=10)# default = 3\n",
        "cs.add_hyperparameters([gamma, gamma_value])\n",
        "# We only activate gamma_value if gamma is set to \"value\"\n",
        "cs.add_condition(InCondition(child=gamma_value, parent=gamma, values=[\"value\"]))\n",
        "# And again we can restrict the use of gamma in general to the choice of the kernel\n",
        "cs.add_condition(InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"]))\n",
        "\n",
        "#hyperParameters for random forest\n",
        "numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "\n",
        "maxDepth = UniformIntegerHyperparameter(\"max_depth\", 2, 10, default_value=2)# The maximum depth of tree\n",
        "min_samples_split = UniformIntegerHyperparameter(\"min_samples_split\", 2, 6, default_value=2)#The min number of samples required to split an node\n",
        "min_samples_leaf = UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 4, default_value=1)#The min number of samples at a leaf\n",
        "maxFeatures = UniformIntegerHyperparameter(\"max_features\", 3, 5, default_value=5)#The number of maximum features\n",
        "cs.add_hyperparameters([numEstimators,maxDepth,min_samples_split,min_samples_leaf,maxFeatures])\n",
        "\n",
        "use_maxDepth = InCondition(child=maxDepth, parent=models, values=[\"randomForest\"])\n",
        "use_min_samples_split = InCondition(child=min_samples_split, parent=models, values=[\"randomForest\"])\n",
        "use_min_samples_leaf = InCondition(child=min_samples_leaf, parent=models, values=[\"randomForest\"])\n",
        "use_maxFeatures = InCondition(child=maxFeatures, parent=models, values=[\"randomForest\"])\n",
        "cs.add_conditions([use_maxDepth,use_min_samples_split,use_min_samples_leaf,use_maxFeatures])\n",
        "\n",
        "#hyperParameters for adaBoost\n",
        "# numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "learningRate = UniformFloatHyperparameter(\"learning_rate\", 0.1, 10, default_value=1)# The learning rate\n",
        "lossFunction = CategoricalHyperparameter(\"loss\", [\"linear\", \"square\", \"exponential\"], default_value=\"linear\")\n",
        "cs.add_hyperparameters([learningRate,lossFunction])\n",
        "\n",
        "use_learningRate = InCondition(child=learningRate, parent=models, values=[\"adaBoost\"])\n",
        "use_lossFunction = InCondition(child=lossFunction, parent=models, values=[\"adaBoost\"])\n",
        "use_numEstimators = InCondition(child=numEstimators,parent=models,values=[\"randomForest\",\"adaBoost\"])\n",
        "cs.add_conditions([use_numEstimators,use_learningRate, use_lossFunction])\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 300,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"})\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = regressor_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=regressor_from_cfg,acquisition_function =EI(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = regressor_from_cfg(incumbent)\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51QCR55V7Es",
        "colab_type": "code",
        "outputId": "78e75478-cade-4372-bb06-b248ea8205ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "#The gamma is always set to value, not \"auto\"\n",
        "# A self implemented AutoML framework with three regressors:svr,random forest,adaboost\n",
        "# Feature engineering,machine learning model selection, hyperparameter optimization\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "rockMassData = pd.read_csv('rock mass properties.csv',sep = ',')\n",
        "subRockMassData = rockMassData[['UCS','BTS','PSI','DPW','Alpha angle','Measured ROP']]\n",
        "subRockMassData['Alpha angle'] = np.sin(subRockMassData['Alpha angle'] * np.pi / 180)\n",
        "totalFeatureLabels = np.array(subRockMassData)\n",
        "def mse(trueOutput,predictOutput):\n",
        "    diff = (trueOutput-predictOutput)\n",
        "    mse = np.mean(diff ** 2)\n",
        "    return mse\n",
        "#Normalization methods selection\n",
        "def getNormalizator(norm_method):\n",
        "    normMethod = None\n",
        "    if norm_method == 'standard':\n",
        "        normMethod = StandardScaler\n",
        "    if norm_method == 'min-max':\n",
        "        normMethod = MinMaxScaler\n",
        "    if norm_method == 'max-abs':\n",
        "        normMethod = MaxAbsScaler\n",
        "    return normMethod\n",
        "\n",
        "#Model selection\n",
        "def getRegressor(modelName):\n",
        "    regressor = None\n",
        "    if modelName == 'randomForest':\n",
        "        regressor = RandomForestRegressor\n",
        "    if modelName == 'adaBoost':\n",
        "        regressor = AdaBoostRegressor\n",
        "    if modelName == 'svr':\n",
        "        regressor = svm.SVR\n",
        "    return regressor        \n",
        "def regressor_from_cfg(cfg):\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "    #Generate model and pop the item\n",
        "    norm_fuck = cfg['norm-method']\n",
        "    cfg.pop('norm-method')\n",
        "#     rockMassData = pd.read_csv('rock mass properties.csv',sep = ',')\n",
        "#     subRockMassData = rockMassData[['UCS','BTS','PSI','DPW','Alpha angle','Measured ROP']]\n",
        "#     subRockMassData['Alpha angle'] = np.sin(subRockMassData['Alpha angle'] * np.pi / 180)\n",
        "#     totalFeatureLabels = np.array(subRockMassData)\n",
        "    norm_constructor = getNormalizator(norm_fuck)\n",
        "    normModel = norm_constructor()\n",
        "    totalFeatureLabels_scaled = normModel.fit_transform(totalFeatureLabels)    \n",
        "    inputs = totalFeatureLabels_scaled[:,:-1]\n",
        "    outputs = totalFeatureLabels_scaled[:,-1]\n",
        "    trainInput,testInput,trainOutput,_ = train_test_split(inputs,outputs,train_size = 121,shuffle=True,random_state =123)\n",
        "#     trainInput = inputs[:121,:]#The random split strategy performs better than the random split strategy\n",
        "#     testInput = inputs[121:,:]\n",
        "#     trainOutput = outputs[:121]\n",
        "#     testOutput = outputs[121:]    \n",
        "    modelName = cfg['modelName']\n",
        "    if modelName == 'svr':\n",
        "        print(cfg)\n",
        "        cfg[\"shrinking\"] = True if cfg[\"shrinking\"] == \"true\" else False\n",
        "        if \"gamma\" in cfg:\n",
        "            cfg[\"gamma\"] = cfg[\"gamma_value\"] if cfg[\"gamma\"] == \"value\" else \"auto\"\n",
        "            cfg.pop(\"gamma_value\", None)  # Remove \"gamma_value\"\n",
        "    regressor = getRegressor(modelName)#Constructor for the specified regressor model    \n",
        "    cfg.pop('modelName')\n",
        "    #Create the regressor model\n",
        "    model = regressor(**cfg)\n",
        "\n",
        "    model.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = model.predict(testInput)\n",
        "    restored = np.zeros((30,6))\n",
        "    restored[:,:5] = testInput\n",
        "    restored[:,5] = predictTestOutput\n",
        "    restored_predict = normModel.inverse_transform(restored)\n",
        "\t\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "#     testMAPE = mape(testOutput,predictTestOutput)\n",
        "    testMSE = mse(totalFeatureLabels[121:,5],restored_predict[:,5])\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "    print\n",
        "    return testMSE\n",
        "#    return testMAPE\n",
        "#     return -testCoef\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\") \n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "#Add the preprocessing option for the AutoML framework TO-DO\n",
        "# Pattern of normalization, The 151 data should be splited sequentially, the former 121 for training\n",
        "#The latter 30 for testing\n",
        "\n",
        "# data prerpocessing\n",
        "norm_methods = CategoricalHyperparameter(\"norm-method\", [\"standard\", \"min-max\",\"max-abs\"], default_value=\"min-max\")\n",
        "# model selection and optimizatio of hyperparameters\n",
        "models = CategoricalHyperparameter(\"modelName\", [\"randomForest\", \"adaBoost\",\"svr\"], default_value=\"svr\")\n",
        "cs.add_hyperparameters([norm_methods,models])\n",
        "\n",
        "#hyperParameters for svr: C, kernel, shrinking, degree <- kernel:poly, coef0 <- poly, sigmoid, gamma <-rbf, \"poly, sigmoid\n",
        "# We define a few possible types of SVM-kernels and add them as \"kernel\" to our cs\n",
        "kernel = CategoricalHyperparameter(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"], default_value=\"poly\")\n",
        "C = UniformFloatHyperparameter(\"C\", 500, 1000.0, default_value=600)#default = 10\n",
        "shrinking = CategoricalHyperparameter(\"shrinking\", [\"true\", \"false\"], default_value=\"true\")\n",
        "cs.add_hyperparameters([kernel,C, shrinking])\n",
        "use_C = InCondition(child=C,parent=models,values=[\"svr\"])\n",
        "use_kernel = InCondition(child=kernel,parent=models,values=[\"svr\"])\n",
        "use_shrinking = InCondition(child=shrinking,parent=models,values=[\"svr\"])\n",
        "cs.add_conditions([use_kernel,use_C,use_shrinking])\n",
        "\n",
        "# Others are kernel-specific, so we can add conditions to limit the searchspace\n",
        "degree = UniformIntegerHyperparameter(\"degree\", 1, 5, default_value=3)     # Only used by kernel poly,default = 3\n",
        "coef0 = UniformFloatHyperparameter(\"coef0\", 0.0, 10.0, default_value=0.0)  # poly, sigmoid, default = 0.0\n",
        "cs.add_hyperparameters([degree, coef0])\n",
        "\n",
        "use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n",
        "use_coef0 = InCondition(child=coef0, parent=kernel, values=[\"poly\", \"sigmoid\"])\n",
        "\n",
        "# use_degree = InCondition(child=degree, parent=models, values=[\"svr\"])\n",
        "# use_coef0 = InCondition(child=coef0, parent=models, values=[\"svr\"])\n",
        "cs.add_conditions([use_degree, use_coef0])\n",
        "\n",
        "# This also works for parameters that are a mix of categorical and values from a range of numbers\n",
        "# For example, gamma can be either \"auto\" or a fixed float\n",
        "gamma = CategoricalHyperparameter(\"gamma\", [\"auto\", \"value\"], default_value=\"auto\")  # only rbf, poly, sigmoid\n",
        "gamma_value = UniformFloatHyperparameter(\"gamma_value\", 0, 20, default_value=3)# default = 3\n",
        "cs.add_hyperparameters([gamma,gamma_value])\n",
        "# We only activate gamma_value if gamma is set to \"value\"\n",
        "cs.add_condition(InCondition(child=gamma_value, parent=gamma, values=[\"value\"]))\n",
        "# And again we can restrict the use of gamma in general to the choice of the kernel\n",
        "cs.add_condition(InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"]))\n",
        "\n",
        "#hyperParameters for random forest\n",
        "numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "\n",
        "maxDepth = UniformIntegerHyperparameter(\"max_depth\", 2, 10, default_value=2)# The maximum depth of tree\n",
        "min_samples_split = UniformIntegerHyperparameter(\"min_samples_split\", 2, 6, default_value=2)#The min number of samples required to split an node\n",
        "min_samples_leaf = UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 4, default_value=1)#The min number of samples at a leaf\n",
        "maxFeatures = UniformIntegerHyperparameter(\"max_features\", 3, 5, default_value=5)#The number of maximum features\n",
        "cs.add_hyperparameters([numEstimators,maxDepth,min_samples_split,min_samples_leaf,maxFeatures])\n",
        "\n",
        "use_maxDepth = InCondition(child=maxDepth, parent=models, values=[\"randomForest\"])\n",
        "use_min_samples_split = InCondition(child=min_samples_split, parent=models, values=[\"randomForest\"])\n",
        "use_min_samples_leaf = InCondition(child=min_samples_leaf, parent=models, values=[\"randomForest\"])\n",
        "use_maxFeatures = InCondition(child=maxFeatures, parent=models, values=[\"randomForest\"])\n",
        "cs.add_conditions([use_maxDepth,use_min_samples_split,use_min_samples_leaf,use_maxFeatures])\n",
        "\n",
        "#hyperParameters for adaBoost\n",
        "# numEstimators = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "learningRate = UniformFloatHyperparameter(\"learning_rate\", 0.1, 10, default_value=1)# The learning rate\n",
        "lossFunction = CategoricalHyperparameter(\"loss\", [\"linear\", \"square\", \"exponential\"], default_value=\"linear\")\n",
        "cs.add_hyperparameters([learningRate,lossFunction])\n",
        "\n",
        "use_learningRate = InCondition(child=learningRate, parent=models, values=[\"adaBoost\"])\n",
        "use_lossFunction = InCondition(child=lossFunction, parent=models, values=[\"adaBoost\"])\n",
        "use_numEstimators = InCondition(child=numEstimators,parent=models,values=[\"randomForest\",\"adaBoost\"])\n",
        "cs.add_conditions([use_numEstimators,use_learningRate, use_lossFunction])\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 150,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"})\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = regressor_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.6f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=regressor_from_cfg,acquisition_function =LCB(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = regressor_from_cfg(incumbent)\n",
        "print(\"Optimized Value: %.6f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'modelName': 'svr', 'C': 600.0, 'kernel': 'poly', 'shrinking': 'true', 'degree': 3, 'gamma': 'auto'}\n",
            "Default Value: 0.187447\n",
            "{'modelName': 'svr', 'C': 600.0, 'kernel': 'poly', 'shrinking': 'true', 'degree': 3, 'gamma': 'auto'}\n",
            "{'modelName': 'svr', 'C': 795.3293265801383, 'kernel': 'rbf', 'shrinking': 'false', 'gamma': 'auto'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d0799b8cafdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n\u001b[1;32m    169\u001b[0m             tae_runner=regressor_from_cfg,acquisition_function =LCB(model=model))\n\u001b[0;32m--> 170\u001b[0;31m \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;31m# print('The final incumbent is:',incumbent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0minc_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smac/facade/smac_facade.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Search for next configuration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# get all found configurations sorted according to acq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mchallengers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36mchoose_next\u001b[0;34m(self, X, Y, incumbent_value)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macq_opt_challengers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mrandom_configuration_chooser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_configuration_chooser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchallengers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smac/optimizer/ei_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, runhistory, stats, num_points, random_configuration_chooser, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         next_configs_by_local_search = self.local_search._maximize(\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mrunhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sls_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         )\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smac/optimizer/ei_optimization.py\u001b[0m in \u001b[0;36m_maximize\u001b[0;34m(self, runhistory, stats, num_points, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             acq_val, configuration = self._one_iter(\n\u001b[0;32m--> 216\u001b[0;31m                 start_point, **kwargs)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Local Search\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smac/optimizer/ei_optimization.py\u001b[0m in \u001b[0;36m_one_iter\u001b[0;34m(self, start_point, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_neighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m                 \u001b[0ms_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0macq_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mConfigSpace/util.pyx\u001b[0m in \u001b[0;36mget_one_exchange_neighbourhood\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mConfigSpace/hyperparameters.pyx\u001b[0m in \u001b[0;36mConfigSpace.hyperparameters.UniformIntegerHyperparameter.get_neighbors\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \"\"\"\n\u001b[1;32m   2617\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2618\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7P3UWYvRtw5",
        "colab_type": "code",
        "outputId": "7aa7d178-cd0e-4b68-84c0-b5b9ae0ea1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "# random forest with gpyopt，poorer performance than smac\n",
        "def rf_gopt_obj(x):     \n",
        "    hyperParameters = {}\n",
        "    hyperParameters['n_estimators'] = int(x[0,0])\n",
        "    hyperParameters['max_depth'] = int(x[0,1])\n",
        "    hyperParameters['min_samples_split'] = int(x[0,2])\n",
        "    hyperParameters['min_samples_leaf'] = int(x[0,3])\n",
        "    hyperParameters['max_features'] = int(x[0,4])\n",
        "#     print(hyperParameters)\n",
        "    rf = RandomForestRegressor(**hyperParameters)    \n",
        "    \n",
        "    rf.fit(trainInput,trainOutput)\n",
        "    predictTestOutput = rf.predict(testInput)\n",
        "    testMAE = mae(testOutput,predictTestOutput)\n",
        "    testMAPE = mape(testOutput,predictTestOutput)\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "    return testMAPE\n",
        "\n",
        "\n",
        "# numTrees = UniformIntegerHyperparameter(\"n_estimators\", 5, 150, default_value=100)#number of estimators\n",
        "# maxDepth = UniformIntegerHyperparameter(\"max_depth\", 2, 10, default_value=2)# The maximum depth of tree\n",
        "# min_samples_split = UniformIntegerHyperparameter(\"min_samples_split\", 2, 6, default_value=2)#The min number of samples required to split an node\n",
        "# min_samples_leaf = UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 4, default_value=1)#The min number of samples at a leaf\n",
        "# maxFeatures = UniformIntegerHyperparameter(\"max_features\", 3, 5, default_value=5)#The number of maximum features\n",
        "\n",
        "numTree_domain_list = [i for i in range(2,200)]\n",
        "maxDepth_domain_list = [i for i in range(2,11)]\n",
        "minSplit_domain_list = [i for i in range(2,10)]\n",
        "minLeaf_domain_list = [i for i in range(1,5)]\n",
        "maxFeatures_domain_list = [i for i in range(2,6)]\n",
        "\n",
        "bounds = [{'name': 'numTrees', 'type': 'discrete', 'domain': tuple(numTree_domain_list)},\n",
        "               {'name': 'maxDepth','type': 'discrete', 'domain': tuple(maxDepth_domain_list)},\n",
        "               {'name': 'min_samples_split',  'type': 'discrete', 'domain':tuple(minSplit_domain_list)},\n",
        "               {'name':'min_samples_leaf','type':'discrete','domain':tuple(minLeaf_domain_list)},\n",
        "               {'name': 'maxFeatures','type': 'discrete', 'domain': tuple(maxFeatures_domain_list)}] \n",
        "\n",
        "acquisition_funcs = ['EI', 'MPI', 'LCB']#Each acquisition functions should be tested\n",
        "# store the convergence history of each acquisition function in a dictionary\n",
        "all_convergence_hist = {}\n",
        "# seed(12345)\n",
        "for acqui_func in acquisition_funcs:\n",
        "    print(acqui_func)   \n",
        "#     myBopt = GPyOpt.methods.BayesianOptimization(f=rf_gopt_obj,domain=bounds,initial_design_numdata=5,\\\n",
        "#                                                  acquisition_type=acqui_func,verbosity=False,evaluator_type='local_penalization',batch_size=8)\n",
        "    myBopt = GPyOpt.methods.BayesianOptimization(f=rf_gopt_obj,domain=bounds,initial_design_numdata=5,\\\n",
        "                                                 acquisition_type=acqui_func,verbosity=False)\n",
        "    myBopt.run_optimization(100)\n",
        "    myBopt.plot_convergence()\n",
        "    print(myBopt.x_opt)\n",
        "    print(myBopt.fx_opt)\n",
        "    evals = myBopt.get_evaluations()\n",
        "    dv_hist = evals[0]\n",
        "    objective_hist = evals[1]\n",
        "    epochs = objective_hist.shape[0]\n",
        "    converge_hist = np.empty((epochs,))\n",
        "    minObj = objective_hist[0,0]\n",
        "    for index in range(epochs):\n",
        "        histIter = objective_hist[index,0]\n",
        "        if minObj >= histIter:\n",
        "            minObj = histIter\n",
        "        converge_hist[index] = minObj\n",
        "    all_convergence_hist[acqui_func] = converge_hist\n",
        "# plot the convergence trace of each acquisition function\n",
        "plt.figure(figsize=(12,8))\n",
        "for (acFunc,hist) in all_convergence_hist.items():\n",
        "    plt.plot(hist,label = acFunc,marker = 's')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Objective function')\n",
        "plt.legend(loc ='best')\n",
        "plt.savefig('results/rf_gpyopt_acquisitions_comparisons.png',format='png')\n",
        "plt.show()\n",
        "#Store the \n",
        "all_acquisitions_df = pd.DataFrame(all_convergence_hist)\n",
        "all_acquisitions_df.to_csv('results/rf_gpyopt_acquisitions_convergence.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EI\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:GP:initializing Y\n",
            "INFO:GP:initializing inference method\n",
            "INFO:GP:adding kernel and likelihood as parameters\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ffe142d16ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                                                  acquisition_type=acqui_func,verbosity=False,evaluator_type='local_penalization',batch_size=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmyBopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPyOpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_gopt_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m                                                 \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macqui_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/GPyOpt/core/bo.py\u001b[0m in \u001b[0;36mrun_optimization\u001b[0;34m(self, max_iter, max_time, eps, context, verbosity, save_models_parameters, report_file, evaluations_file, models_file)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# --- Evaluate *f* in X, augment Y and update cost function (if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# --- Update current evaluation time and function evaluations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/GPyOpt/core/bo.py\u001b[0m in \u001b[0;36mevaluate_objective\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mEvaluates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggested_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cost_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggested_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36m_eval_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mst_time\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-ffe142d16ee9>\u001b[0m in \u001b[0;36mrf_gopt_obj\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpredictTestOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtestMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictTestOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    315\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[1;32m    316\u001b[0m                                           random_state=random_state)\n\u001b[0;32m--> 317\u001b[0;31m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    315\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[1;32m    316\u001b[0m                                           random_state=random_state)\n\u001b[0;32m--> 317\u001b[0;31m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         estimator.set_params(**{p: getattr(self, p)\n\u001b[1;32m    128\u001b[0m                                 for p in self.estimator_params})\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     60\u001b[0m                             % (repr(estimator), type(estimator)))\n\u001b[1;32m     61\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[1;32m    165\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl8g3yU7Bkqw",
        "colab_type": "code",
        "outputId": "7bcf3e88-8973-4d8d-fb18-b1d87aab6c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# try a random forest algorithm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators =100,max_depth = 5,min_samples_leaf = 2,random_state=123,warm_start =True,bootstrap =True )\n",
        "rf.fit(trainInput,trainOutput)\n",
        "predictTestOutput = rf.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "testMAPE = mape(testOutput,predictTestOutput)\n",
        "print(testMAPE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.843931196987628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP8oNO2hKNyn",
        "colab_type": "code",
        "outputId": "5cd8fadb-84c2-4f95-d5d4-85d26416dbec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#try a adaboost algorithm\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "adaBoost = AdaBoostRegressor(n_estimators = 15,learning_rate=1.0, loss='linear')\n",
        "adaBoost.fit(trainInput,trainOutput)\n",
        "predictTestOutput = adaBoost.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "testMAPE = mape(testOutput,predictTestOutput)\n",
        "print(testMAPE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.905318435123439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZfbs4f-M0FP",
        "colab_type": "code",
        "outputId": "3fa8d6f2-8f2b-4f36-a6d5-2a20a043e9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#bagging regressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "bagRegressor = BaggingRegressor(n_estimators=40, max_samples=0.8,max_features=1.0)\n",
        "bagRegressor.fit(trainInput,trainOutput)\n",
        "predictTestOutput = bagRegressor.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "testMAPE = mape(testOutput,predictTestOutput)\n",
        "print(testMAPE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.328756543864154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tinw4OPUI-1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybrTgNr3oRV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SMAC keras,MLP\n",
        "def mlp_from_cfg(cfg):\n",
        "#     cfg = {k : cfg1[k] for k in cfg1 if cfg1[k]}\n",
        "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
        "#     print(cfg)\n",
        "    model = Sequential()\n",
        "    for index in range(cfg['numLayer']):\n",
        "        if index == 0:\n",
        "            print(cfg['count1'])\n",
        "            model.add(Dense(cfg['count1'],input_dim=5,activation='relu'))#First hidden layer\n",
        "        else:\n",
        "            countKey = 'count' + str(index+1)\n",
        "            print(cfg[countKey])\n",
        "            model.add(Dense(cfg[countKey],activation='relu'))   \n",
        "    #Add a output layer layer \n",
        "    model.add(Dense(1,activation='linear'))#output layer\n",
        "    \n",
        "    model.compile(loss='mape', optimizer='adam', metrics=['mape'])\n",
        "#     model.summary()\n",
        "    model.fit(trainInput, trainOutput, epochs=cfg['numEpoch'], batch_size=20, verbose=0, shuffle=False)\n",
        "    \n",
        "    predictTestOutput = model.predict(testInput)\n",
        "#     testMAE = mae(testOutput,predictTestOutput)\n",
        "    testMAPE = mape(testOutput,predictTestOutput)\n",
        "#     print('Test MAE: %.5f, Test MAPE: %.5f'%(testMAE,testMAPE))\n",
        "#     testCoef = coef(testOutput,predictTestOutput)\n",
        "    return testMAPE\n",
        "#     return -testCoef\n",
        "\n",
        "\n",
        "#logger = logging.getLogger(\"SVMExample\")\n",
        "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
        "\n",
        "# Build Configuration Space which defines all parameters and their ranges\n",
        "cs = ConfigurationSpace()\n",
        "\n",
        "numLayer = UniformIntegerHyperparameter(\"numLayer\",1,4,default_value=1)\n",
        "numEpoch = UniformIntegerHyperparameter(\"numEpoch\",10,20,default_value=20)\n",
        "\n",
        "count1 = UniformIntegerHyperparameter(\"count1\", 3, 4, default_value=3)\n",
        "count2 = UniformIntegerHyperparameter(\"count2\", 3, 4, default_value=3)\n",
        "count3 = UniformIntegerHyperparameter(\"count3\", 3, 4, default_value=3)\n",
        "count4 = UniformIntegerHyperparameter(\"count4\", 3, 4, default_value=3)\n",
        "cs.add_hyperparameters([numLayer,numEpoch,count1,count2,count3,count4])\n",
        "\n",
        "#adding dependicies\n",
        "use_count2 = InCondition(child=count2, parent=numLayer, values=[2])\n",
        "use_count3 = InCondition(child=count3, parent=numLayer, values=[3])\n",
        "use_count4 = InCondition(child=count4, parent=numLayer, values=[4])\n",
        "cs.add_conditions([use_count2,use_count3,use_count4])\n",
        "\n",
        "# Scenario object\n",
        "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
        "                     \"runcount-limit\": 150,  # maximum function evaluations\n",
        "                     \"cs\": cs,               # configuration space\n",
        "                     \"deterministic\": \"true\"\n",
        "                     })\n",
        "types, bounds = get_types(scenario.cs, scenario.feature_array)\n",
        "rng =  np.random.RandomState(1)\n",
        "\n",
        "model = RandomForestWithInstances(types=types,bounds=bounds,\\\n",
        "                                              instance_features=scenario.feature_array,\\\n",
        "                                              seed=rng.randint(MAXINT),\\\n",
        "                                              pca_components=scenario.PCA_DIM,\\\n",
        "                                              log_y=scenario.transform_y in [\"LOG\", \"LOGS\"],\\\n",
        "                                              num_trees=scenario.rf_num_trees,\\\n",
        "                                              do_bootstrapping=scenario.rf_do_bootstrapping,\\\n",
        "                                              ratio_features=scenario.rf_ratio_features,\\\n",
        "                                              min_samples_split=scenario.rf_min_samples_split,\\\n",
        "                                              min_samples_leaf=scenario.rf_min_samples_leaf,\\\n",
        "                                              max_depth=scenario.rf_max_depth)\n",
        "\n",
        "# Example call of the function\n",
        "# It returns: Status, Cost, Runtime, Additional Infos\n",
        "def_value = mlp_from_cfg(cs.get_default_configuration())\n",
        "print(\"Default Value: %.2f\" % (def_value))\n",
        "\n",
        "# smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "#             tae_runner=svm_from_cfg,acquisition_function =EI(model=model))\n",
        "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
        "            tae_runner=mlp_from_cfg,acquisition_function =LCB(model=model))\n",
        "incumbent = smac.optimize()\n",
        "# print('The final incumbent is:',incumbent)\n",
        "inc_value = mlp_from_cfg(incumbent)\n",
        "\n",
        "print(\"Optimized Value: %.2f\" % (inc_value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQS1I0EC_4Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#grid search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Epi4BuZ_8QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za6VPwiV_-MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#heuristic methods"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}